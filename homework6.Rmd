---
title: "Homework 6"
author: "Laura Cosgrove"
date: "11/22/2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(modelr)     
library(broom)      

```

## Problem 1

The Washington Post gathered homicide data on large U.S. cities, and made the data public as part of their investigation. I'll reproduce some work from last time: 

```{r}
homicide_data <- 
  read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv") %>% 
  mutate(city_state = str_c(city, state, sep = ", "),
          resolution = factor(case_when(
            disposition == "Closed without arrest" ~ "unsolved",
            disposition == "Open/No arrest"        ~ "unsolved",
            disposition == "Closed by arrest"      ~ "solved"
          ), levels = c("unsolved", "solved")),
         victim_age = as.numeric(victim_age),
         victim_sex = factor(victim_sex)
         ) %>% 
  filter(!city_state %in% c("Tulsa, AL","Phoenix, AZ", "Dallas, TX", "Kansas City, MO")) %>% 
  mutate(victim_race = factor(case_when(
          victim_race == "White" ~ "white",
          victim_race == "Black" ~ "non-white",
          victim_race == "Hispanic" ~ "non-white",
          victim_race == "Other" ~ "non-white",
          victim_race == "Unknown" ~ "NA"), 
        levels = c("white", "non-white", "NA")
         ))
```

I'll look more closely into Baltimore

Create a city_state variable (e.g. “Baltimore, MD”), and a binary variable indicating whether the homicide is solved. Omit cities Dallas, TX; Phoenix, AZ; and Kansas City, MO – these don’t report victim race. Also omit Tulsa, AL – this is a data entry mistake. Modifiy victim_race to have categories white and non-white, with white as the reference category. Be sure that victim_age is numeric. check

For the city of Baltimore, MD, use the glm function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race (as just defined) as predictors. Save the output of glm as an R object; apply the broom::tidy to this object; and obtain the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing non-white victims to white victims keeping all other variables fixed.

```{r}
glm_baltimore <- 
  homicide_data %>% 
  filter(victim_race != "NA",
         city_state == "Baltimore, MD") %>% 
  glm(resolution ~ victim_age + victim_race + victim_sex, family = "binomial", data = .)

broom::tidy(glm_baltimore, conf.int = TRUE, exponentiate = TRUE) %>% 
  filter(term == "victim_racenon-white") %>% 
  select(term, estimate, conf.low, conf.high) %>% 
  rename("Odds Ratio" = estimate) %>% 
  knitr::kable(digits = 3)

```


Now run glm for each of the cities in your dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing non-white victims to white victims. Do this within a “tidy” pipeline, making use of purrr::map, list columns, and unnest as necessary to create a dataframe with estimated ORs and CIs for each city.

```{r}
glm_homicides = function(df) {
  glm(resolution ~ victim_age + victim_race + victim_sex, family = "binomial", data = df)
}

glm_homicide_data <- homicide_data %>% 
  group_by(city_state) %>% 
  select(city_state, resolution, victim_age, victim_race, victim_sex) %>% 
  nest() %>% 
  mutate(glm = map(data, ~glm(resolution ~ victim_age + victim_race + victim_sex, family = "binomial", data = .x))) %>% 
  select(city_state, glm) %>% 
  mutate(glm = map(glm, broom::tidy)) %>% 
  unnest() %>% 
  filter(term == "victim_racenon-white") %>% 
  mutate(odds_ratio = exp(estimate), 
          or_lower = exp(estimate - 1.96*std.error),
          or_upper = exp(estimate + 1.96*std.error), 
          city_state = fct_reorder(city_state, estimate))

glm_homicide_data %>% 
  ggplot(aes(x = city_state, y = odds_ratio)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = or_lower, ymax = or_upper)) + 
  geom_hline(yintercept = 1.0, linetype = "dashed", color = "blue") + 
  coord_flip() + 
  labs(y = "Odds Ratio", 
       title = "Odds Ratio for Solving Homicides if Victim Non-White",
       caption = "Data from Washington Post. Victim sex and age held constant.")
```


Create a plot that shows the estimated ORs and CIs for each city. Organize cities according to estimated OR, and comment on the plot.

## Problem 2

In this probelm, you will analyze data gathered to understand the effects of several variables on a child’s birthweight. This dataset, available here, consists of roughly 4000 children and includes the following variables:

babysex: baby’s sex (male = 1, female = 2)
bhead: baby’s head circumference at birth (centimeters) ** exclude?
blength: baby’s length at birth (centimeteres) ** exclude?
bwt: baby’s birth weight (grams) **outcome
delwt: mother’s weight at delivery (pounds) 
fincome: family monthly income (in hundreds, rounded) **
frace: father’s race (1= White, 2 = Black, 3 = Asian, 4 = Puerto Rican, 8 = Other, 9 = Unknown) **
gaweeks: gestational age in weeks **
malform: presence of malformations that could affect weight (0 = absent, 1 = present) **
menarche: mother’s age at menarche (years) 
mheigth: mother’s height (inches) 
momage: mother’s age at delivery (years) **
mrace: mother’s race (1= White, 2 = Black, 3 = Asian, 4 = Puerto Rican, 8 = Other)
parity: number of live births prior to this pregnancy **
pnumlbw: previous number of low birth weight babies **
pnumgsa: number of prior small for gestational age babies **
ppbmi: mother’s pre-pregnancy BMI **
ppwt: mother’s pre-pregnancy weight (pounds)
smoken: average number of cigarettes smoked per day during pregnancy **
wtgain: mother’s weight gain during pregnancy (pounds) **

Load and clean the data for regression analysis (i.e. convert numeric to factor where appropriate, check for missing data, etc.).

Propose a regression model for birthweight. This model may be based on a hypothesized structure for the factors that underly birthweight, on a data-driven model-building process, or a combination of the two. Describe your modeling process and show a plot of model residuals against fitted values – use add_predictions and add_residuals in making this plot.

```{r}
birthweight_data <- read_csv("./data/birthweight.csv") %>% 
  mutate(babysex = factor(babysex, labels = c("male", "female")),
         frace = factor(frace, levels = c(1, 2, 3, 4, 8), labels = c("White", "Black", "Asian", "Puerto Rican", "Other")),
         mrace = factor(mrace, levels = c(1, 2, 3, 4), labels = c("White", "Black", "Asian", "Puerto Rican")),
         malform = factor(malform, labels = c("absent", "present"))
         )
```

My model-building approach will be step-wise backward elimination: the maximum number of variables will be included at the outset, and the least significant variables will be iteratively eliminated. Since the goal is exploratory, to understand the effects of several variables on birthweight, I chose a method that will allow for a generous/inclusive set of variables.

My first step will be to examine the variables list to detect those which cannot be expected to be independent (e.g. pre-pregnancy BMI and pre-pregnancy weight) and nominate one (or more) of them for exclusion to ensure variables which are clearly not independent are not included together in a model. To check this, I will create a correlation matrix of all variables to note if there are other interactions I missed:

```{r}
birthweight_data %>% 
  select(bwt, everything(), -babysex, -frace, -mrace, -malform, -pnumlbw, -pnumsga) %>% #pnumlbw and pnumsga dropped because of a high number of missing values, correlations not computed
  cor() %>% 
  knitr::kable(digits = 2)
```


For continuous variables, there is high predictor correlation, providing evidence of multicollinearity, between:
* bhead and blength;
* ppwt and delwt and ppbmi

Of the first, I'll keep `bhead` (baby's head circumfrence) because of its higher correlation with the outcome, baby weight. Of the second, I'll keep `delwt` because of its comparative higher correlation with baby weight as well.

For categorical variables, there is likely an interaction between `frace` and `mrace`. I'll exclude the father's race from the model because it seems less relevant, and note to explore at a later date.

Next, I'll plot the distribution of the outcome to check for a reasonable normality assumption.

```{r}
birthweight_data %>% 
  ggplot(aes(x = bwt)) + 
  geom_histogram() + 
  labs( x = "Weight at Birth (grams)")
```

The outcome is not perfectly normal, but it's close enough to be sufficient.

I'll start by including all variables in the model aside from the above-decided exclusions:

```{r}
birthweight_data %>% 
  lm(bwt ~ bhead + delwt + fincome + gaweeks + malform + menarche + mheight + momage + mrace + parity + pnumlbw + pnumsga + smoken + wtgain, data = .) %>% 
  tidy() %>% 
  arrange(p.value)
```

`momage` is first to remove.

```{r}
birthweight_data %>% 
  lm(bwt ~ bhead + delwt + fincome + gaweeks + malform + menarche + mheight + mrace + parity + smoken + wtgain, data = .) %>% 
  tidy() %>% 
  arrange(p.value)
```

`fincome` is also insignificant.

```{r}
birthweight_data %>% 
  lm(bwt ~ bhead + delwt + gaweeks + malform + menarche + mheight + mrace + parity + smoken + wtgain, data = .) %>% 
  tidy() %>% 
  arrange(p.value)
```
  
Dropping `malform` as the presence is insignificant. This is surprising!

```{r}
birthweight_data %>% 
  lm(bwt ~ bhead + delwt + gaweeks + menarche + mheight + mrace + parity + smoken + wtgain, data = .) %>% 
  tidy() %>% 
  arrange(p.value)


```

Compared to the reference category of the mother's race being white, the mother's race being asian has an insignificant effect on birthweight. This is a possible candidate for grouping white and asian mothers together, but since the mother's race being black has a very significant effect on the birthweight, I will keep mrace in the model.

The effects `menarche` and `parity` are above the 5% significance level, but since the model is for exploratory and descriptive purposes, I will examine the model diagnostics before eliminating them.


```{r}
generous_model <-  lm(bwt ~ bhead + delwt + gaweeks + menarche + mheight + mrace + parity + smoken + wtgain, data = birthweight_data)

birthweight_data %>% 
  add_predictions(generous_model) %>% 
  add_residuals(generous_model) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() + 
  geom_smooth(se = FALSE) + 
  labs(title = "Predicted values vs. residuals plot for combination model", 
       x = "Predicted value", 
       y = "Residual")
```

The model poorly predicts outcomes at low birthweights, under 2000 grams. Influential points seem to be present, particularly at lower birthweights. However, in the most common range for birthweights, the residuals appear to be evenly spread around zero, indicating np violation of error assumptions in those ranges.

### Comparing model

Compare your model to two others:

One using length at birth and gestational age as predictors (main effects only)
One using head circumference, length, sex, and all interactions (including the three-way interaction) between these
Make this comparison in terms of the cross-validated prediction error; use crossv_mc and functions in purrr as appropriate.

Note that although we expect your model to be reasonable, model building itself is not a main idea of the course and we don’t necessarily expect your model to be “optimal”.

```{r}
twopred_mod <- lm(bwt ~ blength + gaweeks, data = birthweight_data)
threeint_mod <- lm(bwt ~ bhead + blength + babysex + bhead:blength + babysex:blength + babysex:bhead, data = birthweight_data)

cv_bweight <- crossv_mc(birthweight_data, 100)

cv_bweight <- cv_bweight %>% 
  mutate(my_mod = map(train, ~lm(bwt ~ bhead + delwt + gaweeks + menarche + mheight + mrace + parity + smoken + wtgain, data = .x)), 
         twopred_mod = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)), 
         threeint_mod = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead:blength + babysex:blength + babysex:bhead, data = .x))) %>% 
  mutate(rmse_my = map2_dbl(my_mod, test, ~rmse(model = .x, data = .y)),
         rmse_twopred = map2_dbl(twopred_mod, test, ~rmse(model = .x, data = .y)),
         rmse_threeint = map2_dbl(threeint_mod, test, ~rmse(model = .x, data = .y)))

cv_bweight %>% 
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() + 
  labs(title = "Violin plots of RMSE", 
       x = "Model", 
       y = "RMSE")


```

The model with three interactions has a lower RMSE. If the goal is to make predictions, I would choose the model that is based on the interactions between the baby's sex, head circumfrence, and length to predict birthweight. However, if the goal is to explore other, non-obvious factors of birthweight, such as mother's race, weight gain during pregnancy, history of smoking, and other factors that might be relevant from clinical guidance and equity of care standpoints, I would work to further optimize my model, perhaps including more interaction factors. 

